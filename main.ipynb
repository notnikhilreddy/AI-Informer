{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from autogen import UserProxyAgent, AssistantAgent\n",
    "from twikit import Client\n",
    "import os\n",
    "\n",
    "keyword = \"Artificial Intelligence\"\n",
    "topic_count = 20\n",
    "article_count = 10\n",
    "max_period_hours = 3\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "GROQ_MODEL_NAME = os.getenv(\"GROQ_MODEL_NAME\")\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "GROQ_API_BASE = os.getenv(\"GROQ_API_BASE\")\n",
    "RELEASE = os.getenv(\"RELEASE\")\n",
    "\n",
    "if(RELEASE == \"PROD\"):\n",
    "    USERNAME = os.getenv(\"XUSERNAME\")\n",
    "    EMAIL = os.getenv(\"XEMAIL\")\n",
    "    PASSWORD = os.getenv(\"XPASSWORD\")\n",
    "else:\n",
    "    USERNAME = os.getenv(\"XUSERNAME_TEST\")\n",
    "    EMAIL = os.getenv(\"XEMAIL_TEST\")\n",
    "    PASSWORD = os.getenv(\"XPASSWORD_TEST\")\n",
    "\n",
    "# Config dictionary\n",
    "llm_config = {\n",
    "    \"cache_seed\": 42,\n",
    "    \"config_list\": [{\n",
    "        \"model\": GROQ_MODEL_NAME,\n",
    "        \"api_key\": GROQ_API_KEY,\n",
    "        \"base_url\": GROQ_API_BASE\n",
    "    }],\n",
    "}\n",
    "\n",
    "# # Initialize client\n",
    "if 'x_client' not in globals():\n",
    "    x_client = Client('en-US')\n",
    "\n",
    "    x_client.login(\n",
    "        auth_info_1=USERNAME,\n",
    "        auth_info_2=EMAIL,\n",
    "        password=PASSWORD\n",
    "    )\n",
    "    print(\"Client initialized\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from newspaper import Article\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def select_random_article(news_list):\n",
    "    if not os.path.isfile('urls.csv'):\n",
    "        df_urls = pd.DataFrame(columns=['urls', 'status'])  # Define the variable with a default value\n",
    "        df_urls.to_csv('urls.csv')\n",
    "    else:\n",
    "        df_urls = pd.read_csv('urls.csv', index_col='Unnamed: 0')\n",
    "    news, article = None, None\n",
    "    \n",
    "    while True:\n",
    "        #remove any news from the news_list if it is already in the csv file\n",
    "        news_list = [news for news in news_list if news['url'] not in df_urls['urls'].values]\n",
    "        print(f'FILTERED NEWS LIST: {news_list}')\n",
    "        if not news_list:\n",
    "            print(\"No more news to select\")\n",
    "            return None, None\n",
    "        \n",
    "        news = random.choice(news_list)\n",
    "        try:\n",
    "            # Code to check if the article is valid\n",
    "            # For example, you can check if the URL is accessible or if the content is not empty\n",
    "            # If the article is valid, return it\n",
    "            # Otherwise, continue to the next iteration of the loop\n",
    "            article = Article(news['url'])\n",
    "            article.download()\n",
    "            article.parse()\n",
    "\n",
    "            if article.text and len(article.text.strip().split('\\n')) > 1:\n",
    "                # Append the URL and status to the DataFrame\n",
    "                df_urls = pd.concat([pd.DataFrame([[news['url'], 'success']], columns=df_urls.columns), df_urls], ignore_index=True)\n",
    "                df_urls.to_csv('urls.csv')\n",
    "                break\n",
    "            else:\n",
    "                df_urls = pd.concat([pd.DataFrame([[news['url'], 'empty']], columns=df_urls.columns), df_urls], ignore_index=True)\n",
    "                df_urls.to_csv('urls.csv')\n",
    "                continue\n",
    "        except Exception as e:\n",
    "            # Append the URL and status to the DataFrame\n",
    "            df_urls = pd.concat([pd.DataFrame([[news['url'], 'error']], columns=df_urls.columns), df_urls], ignore_index=True)\n",
    "            df_urls.to_csv('urls.csv')\n",
    "            print(f\"Error selecting article: {str(e)}\")\n",
    "            continue\n",
    "    return news, article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from gnews import GNews\n",
    "from pyshorteners import Shortener\n",
    "\n",
    "#delete .cache/topics.csv to reset the topics\n",
    "if os.path.isfile('.cache/topics.csv'):\n",
    "    os.remove('.cache/topics.csv')\n",
    "\n",
    "def topic_selection_tool(topics_list: Annotated[list, \"The list of topics\"] = None) -> str:\n",
    "    #set df_topics topic column from the topics_list and set status to pending if it's not already in the df_topics\n",
    "    if os.path.isfile('.cache/topics.csv'):\n",
    "        df_topics = pd.read_csv('.cache/topics.csv', index_col='Unnamed: 0')\n",
    "    else:\n",
    "        df_topics = pd.DataFrame(columns=['topic', 'status'])  # Define the variable with a default value\n",
    "    if topics_list:\n",
    "        for topic in topics_list:\n",
    "            if topic not in df_topics['topic'].values:\n",
    "                df_topics = pd.concat([df_topics, pd.DataFrame([[topic, 'pending']], columns=df_topics.columns)], ignore_index=True)\n",
    "    \n",
    "    topics_list = df_topics[df_topics['status'] == 'pending']['topic'].values.tolist()\n",
    "    if(len(topics_list) == 0):\n",
    "        return \"No more topics to select\"\n",
    "    \n",
    "    topic_selected = random.choice(topics_list)\n",
    "    df_topics.loc[df_topics['topic'] == topic_selected, 'status'] = 'selected'\n",
    "    \n",
    "    df_topics.to_csv('.cache/topics.csv')\n",
    "    return topic_selected\n",
    "\n",
    "def get_news_article_tool(topic: Annotated[str, \"The topic to collect news on\"], count: Annotated[int, \"The number of news articles to collect from the internet\"]) -> str:\n",
    "    google_news = GNews()\n",
    "    google_news.max_results = count  # number of responses across a keyword\n",
    "    google_news.language = 'english'  # News in a specific language\n",
    "    period_hours = 1\n",
    "    \n",
    "    while True:\n",
    "        google_news.period = f'{period_hours}h'  # Adjust period in hours\n",
    "        news_list = google_news.get_news(topic)\n",
    "        news, article = select_random_article(news_list)\n",
    "        print(f'NEWS LIST: {news_list}')\n",
    "\n",
    "        if news and article:\n",
    "            s = Shortener(timeout=5)\n",
    "            short_url = s.tinyurl.short(news['url'])\n",
    "\n",
    "            result = (\n",
    "    \"\"\"TITLE: {title}\n",
    "\n",
    "CONTENT: {content}\n",
    "\n",
    "SOURCE: {url}\"\"\"\n",
    "            ).format(\n",
    "                title=news['title'],\n",
    "                content=article.text.replace('\\n\\n', '\\n'),\n",
    "                url=short_url\n",
    "            )\n",
    "            return result\n",
    "        if period_hours >= max_period_hours:\n",
    "            topic = topic_selection_tool(None)\n",
    "            period_hours = 0\n",
    "        period_hours += 1  # Increase the period by 1 hour and try again\n",
    "    \n",
    "# def get_trending_tweets_tool(topic: Annotated[str, \"The topic to retrieve tweets on\"], count: Annotated[int, \"The number of top tweets to collect\"]) -> str:\n",
    "#     tweets = []\n",
    "#     tweets_batch = x_client.search_tweet(query=topic, product='Top', count=count)\n",
    "\n",
    "#     while len(tweets) < count:\n",
    "#         for tweet in tweets_batch:\n",
    "#             if tweet.lang == 'en' and 't.co/' in tweet.full_text:\n",
    "#                 tweets.append(tweet.full_text)\n",
    "#                 if len(tweets) >= count:\n",
    "#                     break\n",
    "#         else:\n",
    "#             tweets_batch = tweets_batch.next()\n",
    "\n",
    "#     return \"\\n\\n\".join(f'Tweet {i+1}: \"{tweet}\"' for i, tweet in enumerate(tweets))\n",
    "\n",
    "def write_tweet_tool(tweet: Annotated[str, \"The tweet to post\"], source: Annotated[str, \"The source URL of the news\"]) -> str:\n",
    "    try:\n",
    "        if 'tinyurl.com' in tweet:\n",
    "            if len(tweet) > 280:\n",
    "                tweet = tweet[:276-len(source)] + '...' + f\"\\n{source}\"\n",
    "        else:\n",
    "            if len(tweet) <= 279-len(source):\n",
    "                tweet += f\"\\n{source}\"\n",
    "            else:\n",
    "                tweet = tweet[:276-len(source)] + '...' + f\"\\n{source}\"\n",
    "        \n",
    "        if RELEASE != \"DEV\":\n",
    "            x_client.create_tweet(\n",
    "                text=tweet,\n",
    "            )\n",
    "        \n",
    "        return f'Tweet posted: \"{tweet}\"'\n",
    "    except Exception as e:\n",
    "        error_message = f\"Failed to post tweet: {str(e)}\"\n",
    "        return error_message\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_selector_agent = AssistantAgent(\n",
    "    \"topic_selector_agent\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=f\"You are good at writing a list of closely related topics to the given topic(including the given topic) and then choose any one out of them. Use the provided tools for both topic selection and to collect new articles.\",\n",
    "    max_consecutive_auto_reply=1\n",
    ")\n",
    "\n",
    "news_collector_agent = AssistantAgent(\n",
    "    \"news_collector_agent\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=f\"You are good at collecting recent news articles about a given topic on the internet. Use the provided tool to collect news about the chosen topic.\",\n",
    "    max_consecutive_auto_reply=1\n",
    ")\n",
    "\n",
    "# news_picker_agent = AssistantAgent(\n",
    "#     \"news_picker_agent\",\n",
    "#     llm_config=llm_config,\n",
    "#     system_message=\"You are good at picking the most interesting news article from a list of given news articles AS IT IS. Always include the source URL link\",\n",
    "#     max_consecutive_auto_reply=1\n",
    "# )\n",
    "\n",
    "# tweets_retriever_agent = AssistantAgent(\n",
    "#     \"tweets_retriever_agent\",\n",
    "#     llm_config=llm_config,\n",
    "#     system_message=\"You are good at retrieving recent tweets about a given topic on twitter. Always include source the URL link. Use the provided tool.\",\n",
    "#     max_consecutive_auto_reply=1\n",
    "# )\n",
    "\n",
    "tweet_writer_agent = AssistantAgent(\n",
    "    \"tweet_writer_agent\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"You are an autonomous twitter bot that's designed to post the latest news for everyone. You are good at posting twitter posts on the given news. Always use simple words. Use the provided tool to post a tweet.\",\n",
    "    max_consecutive_auto_reply=1\n",
    ")\n",
    "\n",
    "\n",
    "user_proxy_agent = UserProxyAgent(\n",
    "    name=\"User\",\n",
    "    system_message=\"You are a helpful AI assistant. Return 'TERMINATE' when the task is done.\",\n",
    "    is_termination_msg=lambda msg: msg.get(\"content\") is not None and \"TERMINATE\" in msg[\"content\"],\n",
    "    human_input_mode=\"NEVER\",\n",
    "    code_execution_config=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.write_tweet_tool(tweet: Annotated[str, 'The tweet to post'], source: Annotated[str, 'The source URL of the news']) -> str>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Register the tool signature with the assistant agent.\n",
    "topic_selector_agent.register_for_llm(name=\"topic_selection_tool\", description=\"Generate a list of topics related to the input topic and return a random topic.\")(topic_selection_tool)\n",
    "news_collector_agent.register_for_llm(name=\"get_news_article_tool\", description=\"Collect news articles about a topic on the internet.\")(get_news_article_tool)\n",
    "# tweets_retriever_agent.register_for_llm(name=\"get_trending_tweets_tool\", description=\"Collect top trending tweets about a topic on twitter.\")(get_trending_tweets_tool)\n",
    "tweet_writer_agent.register_for_llm(name=\"write_tweet_tool\", description=\"Write a twitter post.\")(write_tweet_tool)\n",
    "\n",
    "# Register the tool function with the user proxy agent.\n",
    "user_proxy_agent.register_for_execution(name=\"topic_selection_tool\")(topic_selection_tool)\n",
    "user_proxy_agent.register_for_execution(name=\"get_news_article_tool\")(get_news_article_tool)\n",
    "# user_proxy_agent.register_for_execution(name=\"get_trending_tweets_tool\")(get_trending_tweets_tool)\n",
    "user_proxy_agent.register_for_execution(name=\"write_tweet_tool\")(write_tweet_tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[34mStarting a new chat....\u001b[0m\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[33mUser\u001b[0m (to topic_selector_agent):\n",
      "\n",
      "Generate a list of 20 topics related to the topic 'Artificial Intelligence' and return a random topic from the list.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/08/2024 01:35:50 PM - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mtopic_selector_agent\u001b[0m (to User):\n",
      "\n",
      "\u001b[32m***** Suggested tool call (call_p3dq): topic_selection_tool *****\u001b[0m\n",
      "Arguments: \n",
      "{\"topics_list\":[\"Artificial Intelligence\",\"Machine Learning\",\"Deep Learning\",\"Neural Networks\",\"Natural Language Processing\",\"Computer Vision\",\"Robotics\",\"Expert Systems\",\"Speech Recognition\",\"Data Mining\",\"Predictive Analytics\",\"Reinforcement Learning\",\"Fuzzy Logic\",\"Genetic Algorithms\",\"Evolutionary Computation\",\"Artificial Neural Networks\",\"Support Vector Machines\",\"Bayesian Networks\",\"Markov Decision Processes\",\"Unsupervised Learning\"]}\n",
      "\u001b[32m*****************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION topic_selection_tool...\u001b[0m\n",
      "\u001b[33mUser\u001b[0m (to topic_selector_agent):\n",
      "\n",
      "\u001b[33mUser\u001b[0m (to topic_selector_agent):\n",
      "\n",
      "\u001b[32m***** Response from calling tool (call_p3dq) *****\u001b[0m\n",
      "Reinforcement Learning\n",
      "\u001b[32m**************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[34mStarting a new chat....\u001b[0m\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[33mUser\u001b[0m (to news_collector_agent):\n",
      "\n",
      "Collect 10 news articles about the given topic from the internet.\n",
      "Context: \n",
      "Reinforcement Learning\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/08/2024 01:35:51 PM - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mnews_collector_agent\u001b[0m (to User):\n",
      "\n",
      "\u001b[32m***** Suggested tool call (call_g2fr): get_news_article_tool *****\u001b[0m\n",
      "Arguments: \n",
      "{\"count\":10,\"topic\":\"Reinforcement Learning\"}\n",
      "\u001b[32m******************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION get_news_article_tool...\u001b[0m\n",
      "FILTERED NEWS LIST: [{'title': 'This AI Paper from Cohere for AI Presents a Comprehensive Study on Multilingual Preference Optimization - MarkTechPost', 'description': 'This AI Paper from Cohere for AI Presents a Comprehensive Study on Multilingual Preference Optimization  MarkTechPost', 'published date': 'Mon, 08 Jul 2024 16:39:31 GMT', 'url': 'https://news.google.com/rss/articles/CBMikAFodHRwczovL3d3dy5tYXJrdGVjaHBvc3QuY29tLzIwMjQvMDcvMDgvdGhpcy1haS1wYXBlci1mcm9tLWNvaGVyZS1mb3ItYWktcHJlc2VudHMtYS1jb21wcmVoZW5zaXZlLXN0dWR5LW9uLW11bHRpbGluZ3VhbC1wcmVmZXJlbmNlLW9wdGltaXphdGlvbi_SAZQBaHR0cHM6Ly93d3cubWFya3RlY2hwb3N0LmNvbS8yMDI0LzA3LzA4L3RoaXMtYWktcGFwZXItZnJvbS1jb2hlcmUtZm9yLWFpLXByZXNlbnRzLWEtY29tcHJlaGVuc2l2ZS1zdHVkeS1vbi1tdWx0aWxpbmd1YWwtcHJlZmVyZW5jZS1vcHRpbWl6YXRpb24vP2FtcA?oc=5&hl=en-US&gl=US&ceid=US:en', 'publisher': {'href': 'https://www.marktechpost.com', 'title': 'MarkTechPost'}}]\n",
      "NEWS LIST: [{'title': 'This AI Paper from Cohere for AI Presents a Comprehensive Study on Multilingual Preference Optimization - MarkTechPost', 'description': 'This AI Paper from Cohere for AI Presents a Comprehensive Study on Multilingual Preference Optimization  MarkTechPost', 'published date': 'Mon, 08 Jul 2024 16:39:31 GMT', 'url': 'https://news.google.com/rss/articles/CBMikAFodHRwczovL3d3dy5tYXJrdGVjaHBvc3QuY29tLzIwMjQvMDcvMDgvdGhpcy1haS1wYXBlci1mcm9tLWNvaGVyZS1mb3ItYWktcHJlc2VudHMtYS1jb21wcmVoZW5zaXZlLXN0dWR5LW9uLW11bHRpbGluZ3VhbC1wcmVmZXJlbmNlLW9wdGltaXphdGlvbi_SAZQBaHR0cHM6Ly93d3cubWFya3RlY2hwb3N0LmNvbS8yMDI0LzA3LzA4L3RoaXMtYWktcGFwZXItZnJvbS1jb2hlcmUtZm9yLWFpLXByZXNlbnRzLWEtY29tcHJlaGVuc2l2ZS1zdHVkeS1vbi1tdWx0aWxpbmd1YWwtcHJlZmVyZW5jZS1vcHRpbWl6YXRpb24vP2FtcA?oc=5&hl=en-US&gl=US&ceid=US:en', 'publisher': {'href': 'https://www.marktechpost.com', 'title': 'MarkTechPost'}}]\n",
      "\u001b[33mUser\u001b[0m (to news_collector_agent):\n",
      "\n",
      "\u001b[33mUser\u001b[0m (to news_collector_agent):\n",
      "\n",
      "\u001b[32m***** Response from calling tool (call_g2fr) *****\u001b[0m\n",
      "TITLE: This AI Paper from Cohere for AI Presents a Comprehensive Study on Multilingual Preference Optimization - MarkTechPost\n",
      "\n",
      "CONTENT: Reddit Vote Flip Share 0 Shares\n",
      "Multilingual natural language processing (NLP) is a rapidly advancing field that aims to develop language models capable of understanding & generating text in multiple languages. These models facilitate effective communication and information access across diverse linguistic backgrounds. This field’s importance lies in its potential to bridge the gap between different language speakers, making technological advancements in AI accessible globally. However, developing such models presents significant challenges due to the complexities of handling multiple languages simultaneously.\n",
      "One of the main issues in multilingual NLP is the predominant focus on a few major languages, such as English and Chinese. This narrow concentration results in a significant performance gap for models when applied to less commonly spoken languages. Consequently, many languages still need to be represented, limiting AI technologies’ applicability and fairness. Addressing this disparity requires innovative approaches to enhance the quality and diversity of multilingual datasets, ensuring that AI models can perform effectively across a broad spectrum of languages.\n",
      "Traditional methods for improving multilingual language models often involve translating preference data from English to other languages. While this strategy helps somewhat, it introduces several problems, including translation artifacts that can degrade model performance. Relying heavily on translation can lead to a lack of diversity in the data, which is crucial for robust model training. Collecting high-quality multilingual preference data through human annotation is a potential solution, but it is both expensive and time-consuming, making it impractical for large-scale applications.\n",
      "Researchers from Cohere For AI have developed a novel, scalable method for generating high-quality multilingual feedback data. This method aims to balance data coverage and improve the performance of multilingual large language models (LLMs). The research team introduced a unique approach that leverages diverse, multilingual prompts and completions generated by multiple LLMs. This strategy not only increases the diversity of the data but also helps avoid the common pitfalls associated with translation artifacts. The models used in this research include Cohere’s Command and Command R+, specifically designed for multilingual capabilities.\n",
      "The methodology involves translating approximately 50,000 English prompts into 22 additional languages using the NLLB 3.3B model. These prompts are then used to generate completions in each language, ensuring high diversity and quality in the data. The research team also compared completions generated directly in the target language to those translated from English, finding that the former significantly reduced the occurrence of translation artifacts. This approach resulted in a diverse set of multilingual preference pairs crucial for effective preference optimization.\n",
      "The performance of the preference-trained model was evaluated against several state-of-the-art multilingual LLMs. The results were impressive, with the preference-trained model achieving a 54.4% win rate against Aya 23 8B, the current leading multilingual LLM in its parameter class. Additionally, the model showed a 69.5% win rate or higher against other widely used models such as Gemma-1.1-7B-it, Meta-Llama3-8B-Instruct, and Mistral-7B-Instruct-v0.3. These results highlight the effectiveness of the researchers’ approach in improving the performance of multilingual LLMs through enhanced preference optimization.\n",
      "Further analysis revealed that increasing the number of languages in the training data consistently improved the model’s performance. For example, training with five languages resulted in a win rate of 54.9% on unseen languages, compared to 46.3% when training only in English. Moreover, online preference optimization methods, such as Reinforcement Learning from Human Feedback (RLHF), proved more effective than offline methods like Direct Preference Optimization (DPO). The online techniques achieved higher win rates, with RLOO outperforming DPO by a margin of 10.6% in some cases.\n",
      "In conclusion, the research conducted by Cohere For AI demonstrates the critical importance of high-quality, diverse, multilingual data in training effective multilingual language models. The innovative methods introduced by the research team address the challenges of data scarcity and quality, resulting in performance improvements across a wide range of languages. The study not only sets a new benchmark for multilingual preference optimization but also underscores the value of online training methods in achieving superior cross-lingual transfer and overall model performance.\n",
      "Check out the Paper. All credit for this research goes to the researchers of this project. Also, don’t forget to follow us on Twitter.\n",
      "Join our Telegram Channel and LinkedIn Group.\n",
      "If you like our work, you will love our newsletter..\n",
      "Don’t Forget to join our 46k+ ML SubReddit\n",
      "\n",
      "SOURCE: https://tinyurl.com/2bskchby\n",
      "\u001b[32m**************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[34mStarting a new chat....\u001b[0m\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[33mUser\u001b[0m (to tweet_writer_agent):\n",
      "\n",
      "Write and post a twitter post about the given news article and link to the source.\n",
      "Context: \n",
      "Reinforcement Learning\n",
      "TITLE: This AI Paper from Cohere for AI Presents a Comprehensive Study on Multilingual Preference Optimization - MarkTechPost\n",
      "\n",
      "CONTENT: Reddit Vote Flip Share 0 Shares\n",
      "Multilingual natural language processing (NLP) is a rapidly advancing field that aims to develop language models capable of understanding & generating text in multiple languages. These models facilitate effective communication and information access across diverse linguistic backgrounds. This field’s importance lies in its potential to bridge the gap between different language speakers, making technological advancements in AI accessible globally. However, developing such models presents significant challenges due to the complexities of handling multiple languages simultaneously.\n",
      "One of the main issues in multilingual NLP is the predominant focus on a few major languages, such as English and Chinese. This narrow concentration results in a significant performance gap for models when applied to less commonly spoken languages. Consequently, many languages still need to be represented, limiting AI technologies’ applicability and fairness. Addressing this disparity requires innovative approaches to enhance the quality and diversity of multilingual datasets, ensuring that AI models can perform effectively across a broad spectrum of languages.\n",
      "Traditional methods for improving multilingual language models often involve translating preference data from English to other languages. While this strategy helps somewhat, it introduces several problems, including translation artifacts that can degrade model performance. Relying heavily on translation can lead to a lack of diversity in the data, which is crucial for robust model training. Collecting high-quality multilingual preference data through human annotation is a potential solution, but it is both expensive and time-consuming, making it impractical for large-scale applications.\n",
      "Researchers from Cohere For AI have developed a novel, scalable method for generating high-quality multilingual feedback data. This method aims to balance data coverage and improve the performance of multilingual large language models (LLMs). The research team introduced a unique approach that leverages diverse, multilingual prompts and completions generated by multiple LLMs. This strategy not only increases the diversity of the data but also helps avoid the common pitfalls associated with translation artifacts. The models used in this research include Cohere’s Command and Command R+, specifically designed for multilingual capabilities.\n",
      "The methodology involves translating approximately 50,000 English prompts into 22 additional languages using the NLLB 3.3B model. These prompts are then used to generate completions in each language, ensuring high diversity and quality in the data. The research team also compared completions generated directly in the target language to those translated from English, finding that the former significantly reduced the occurrence of translation artifacts. This approach resulted in a diverse set of multilingual preference pairs crucial for effective preference optimization.\n",
      "The performance of the preference-trained model was evaluated against several state-of-the-art multilingual LLMs. The results were impressive, with the preference-trained model achieving a 54.4% win rate against Aya 23 8B, the current leading multilingual LLM in its parameter class. Additionally, the model showed a 69.5% win rate or higher against other widely used models such as Gemma-1.1-7B-it, Meta-Llama3-8B-Instruct, and Mistral-7B-Instruct-v0.3. These results highlight the effectiveness of the researchers’ approach in improving the performance of multilingual LLMs through enhanced preference optimization.\n",
      "Further analysis revealed that increasing the number of languages in the training data consistently improved the model’s performance. For example, training with five languages resulted in a win rate of 54.9% on unseen languages, compared to 46.3% when training only in English. Moreover, online preference optimization methods, such as Reinforcement Learning from Human Feedback (RLHF), proved more effective than offline methods like Direct Preference Optimization (DPO). The online techniques achieved higher win rates, with RLOO outperforming DPO by a margin of 10.6% in some cases.\n",
      "In conclusion, the research conducted by Cohere For AI demonstrates the critical importance of high-quality, diverse, multilingual data in training effective multilingual language models. The innovative methods introduced by the research team address the challenges of data scarcity and quality, resulting in performance improvements across a wide range of languages. The study not only sets a new benchmark for multilingual preference optimization but also underscores the value of online training methods in achieving superior cross-lingual transfer and overall model performance.\n",
      "Check out the Paper. All credit for this research goes to the researchers of this project. Also, don’t forget to follow us on Twitter.\n",
      "Join our Telegram Channel and LinkedIn Group.\n",
      "If you like our work, you will love our newsletter..\n",
      "Don’t Forget to join our 46k+ ML SubReddit\n",
      "\n",
      "SOURCE: https://tinyurl.com/2bskchby\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/08/2024 01:35:53 PM - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mtweet_writer_agent\u001b[0m (to User):\n",
      "\n",
      "\u001b[32m***** Suggested tool call (call_8q2h): write_tweet_tool *****\u001b[0m\n",
      "Arguments: \n",
      "{\"tweet\":\"New AI paper from Cohere for AI presents a comprehensive study on multilingual preference optimization. Check it out here: https://tinyurl.com/2bskchby  #AI #ML #NLP\",\"source\":\"MarkTechPost - Reinforcement Learning: TITLE: This AI Paper from Cohere for AI Presents a Comprehensive Study on Multilingual Preference Optimization - MarkTechPost\"}\n",
      "\u001b[32m*************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION write_tweet_tool...\u001b[0m\n",
      "\u001b[33mUser\u001b[0m (to tweet_writer_agent):\n",
      "\n",
      "\u001b[33mUser\u001b[0m (to tweet_writer_agent):\n",
      "\n",
      "\u001b[32m***** Response from calling tool (call_8q2h) *****\u001b[0m\n",
      "Tweet posted: \"New AI paper from Cohere for AI presents a comprehensive study on multilingual preference optimization. Check it out here: https://tinyurl.com/2bskchby  #AI #ML #NLP\"\n",
      "\u001b[32m**************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    user_proxy_agent.initiate_chats([\n",
    "            {\n",
    "                \"recipient\": topic_selector_agent,\n",
    "                \"message\": f\"Generate a list of {topic_count} topics related to the topic '{keyword}' and return a random topic from the list.\",\n",
    "                \"clear_history\": True,\n",
    "                \"silent\": False,\n",
    "                \"summary_method\": \"last_msg\"\n",
    "            },\n",
    "            {\n",
    "                \"recipient\": news_collector_agent,\n",
    "                \"message\": f\"Collect {article_count} news articles about the given topic from the internet.\",\n",
    "                \"clear_history\": True,\n",
    "                \"silent\": False,\n",
    "                \"summary_method\": \"last_msg\"\n",
    "            },\n",
    "            # {\n",
    "            #     \"recipient\": news_picker_agent,\n",
    "            #     \"message\": \"Pick the most interesting news article:\",\n",
    "            #     \"clear_history\": True,\n",
    "            #     \"silent\": False,\n",
    "            #     \"summary_method\": \"reflection_with_llm\",\n",
    "            # },\n",
    "            # {\n",
    "            #     \"recipient\": tweets_retriever_agent,\n",
    "            #     \"message\": f\"Retrieve the top {count} trending tweets about the topic '{topic_selected}' from twitter:\",\n",
    "            #     \"clear_history\": True,\n",
    "            #     \"silent\": False,\n",
    "            #     \"summary_method\": \"last_msg\",\n",
    "            # },\n",
    "            {\n",
    "                \"recipient\": tweet_writer_agent,\n",
    "                \"message\": \"Write and post a twitter post about the given news article and link to the source.\",\n",
    "                \"clear_history\": True,\n",
    "                \"silent\": False,\n",
    "                \"summary_method\": \"last_msg\"\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tweetbot-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
